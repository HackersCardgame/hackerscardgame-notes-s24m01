Done!
bonsi@gpu:~/oobabooga_linux$ ./start_linux.sh

bin /home/bonsi /oobabooga_linux/installer_files/env/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cudal17.so
INFO: Loading chharlesonfire_ggml-vicuna-7b-4bit...

ERROR:Could not find the quantized model in .pt or .safetensors format, exiting...

Done!
bonsi@gpu:~/oobabooga_linux$ ff
